{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader # For loading documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # For splitting text (corpus) into smaller chunks\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.llms import CTransformers # Using ctransfomers since we are using a quantized model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob = \"*.pdf\",\n",
    "                    loader_cls = PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into smaller chunks\n",
    "\n",
    "def text_splitter(data):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    split_data = splitter.split_documents(data)\n",
    "    return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = text_splitter(extract_data)\n",
    "print(\"The length of the chunks is:\", len(split_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload embedding model\n",
    "def download_embedding():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample conversion of text to embeddings\n",
    "\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PINECONE_API_KEY'] = \"d0ccc28f-3d45-4cff-989a-ff83b043add8\"\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "vectorstore = PineconeVectorStore(embedding = embeddings, index_name = index_name)\n",
    "\n",
    "# For creating a sementic index if it does not exist.\n",
    "# vectorstore = PineconeVectorStore.from_documents(split_data, embeddings, index_name = index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the treatment for diabetes?\"\n",
    "\n",
    "similar_docs = vectorstore.similarity_search(query)\n",
    "print(similar_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "print(type(retriever))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model = \"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                    model_type = \"llama\",\n",
    "                    config = {'max_new_tokens': 512,\n",
    "                              'temperature': 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", prompt_template), \n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is acne?\"})\n",
    "print(\"Response:\", result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
